{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaselineWithModelSelection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/QmuQb4qV4eDpOZd95gGY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sakha-Language-Processing/Model-Selection/blob/main/BaselineWithModelSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA-Ne2c0Bt6u"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "def transform(dataset):\n",
        "    dataset.loc[:,'hour'] = pd.to_datetime(dataset['datetime']).dt.hour     \n",
        "    dataset.loc[:,'day'] = pd.to_datetime(dataset['datetime']).dt.day   \n",
        "    dataset.loc[:,'month'] = pd.to_datetime(dataset['datetime']).dt.month   \n",
        "    dataset.loc[:,'year'] = pd.to_datetime(dataset['datetime']).dt.year    \n",
        "    dataset.loc[:,'weekday'] = pd.to_datetime(dataset['datetime']).dt.dayofweek  \n",
        "    dataset.loc[:,'hour_sin'] = np.sin(2 * np.pi * dataset['hour']/24.0)   \n",
        "    dataset.loc[:,'hour_cos'] = np.cos(2 * np.pi * dataset['hour']/24.0)\n",
        "\n",
        "\n",
        "    numeric_cols = [cname for cname in dataset.columns if dataset[cname].dtype in ['int64', 'float64', 'bool']]\n",
        "    return dataset[numeric_cols]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_log_error, mean_squared_error, mean_absolute_error\n",
        "import statistics\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression \n",
        "from sklearn.svm import LinearSVR, SVR\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.model_selection import GridSearchCV\n",
        " \n",
        "\n",
        "X, y = transform(df[df.columns[:-3]]).copy(), df['count'].apply(np.log1p)\n",
        "X = X.fillna(0)\n",
        "N, results, predictions = 30, [], []\n",
        "\n",
        "for i in range(N):\n",
        "    print(i,end='') \n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "    model = xgb.XGBRegressor(n_estimators=150,max_depth=5, learning_fate=0.1,\n",
        "                             reg_lambda=4.0,reg_alpha=4.0, min_child_weight=10, \n",
        "                             min_split_loss=20)\n",
        "#     model.fit(X_train, y_train, eval_metric='rmse', early_stopping_rounds=10, \n",
        "#               eval_set=[(X_val, y_val)], verbose=False)\n",
        "\n",
        "#     model = LinearRegression() # rmsle =1.1\n",
        "#     model = SVR() \n",
        "#     model = LinearSVR()          \n",
        "#     model = GradientBoostingRegressor() # rmsle =0.75\n",
        "#     model = DecisionTreeRegressor() #0.433\n",
        "#     model = DecisionTreeRegressor(max_depth=13, min_samples_split=10,\n",
        "#         min_samples_leaf=10) #0.39\n",
        "    model = RandomForestRegressor(max_depth=13, n_estimators=35, #0.34\n",
        "                                  min_samples_split=10, min_samples_leaf=10)\n",
        "   \n",
        "    model.fit(X_train, y_train) \n",
        "    y_prediction = np.maximum(model.predict(X_val), 0)\n",
        "    \n",
        "    results.append(np.sqrt(mean_squared_error(y_val,y_prediction)))\n",
        "    predictions.append(model.predict(transform(test)))\n",
        "    \n",
        "print(' ',sum(results)/N, mean_absolute_error(results,[sum(results)/N]*len(results)))\n",
        "\n",
        "rating = []\n",
        "for i in range(len(test)):\n",
        "     rating.append(sum([pred[i] for pred in predictions])/N) \n",
        "\n",
        "\n",
        "y_prediction = np.array([np.max(np.exp(r)-1.0,0) for r in rating])         \n",
        "submission.loc[:,'count'] = y_prediction  \n",
        "submission.to_csv('my_results.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}